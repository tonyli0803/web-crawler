{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "#using python3\n",
    "import sys,requests\n",
    "\n",
    "from selenium import webdriver\n",
    "import time, re\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_path = \".\\chromedriver.exe\" #chromedriver.exe執行檔所存在的路徑\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "driver.get('https://udn.com/news/breaknews/1')\n",
    "sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###load上一次開始爬的新聞的相關資料\n",
    "\n",
    "timestamp = []\n",
    "date_last_time = ''\n",
    "url__last_time  = ''\n",
    "with open(\"udn_news_timestamp.txt\") as f:\n",
    "\ttmp = []\n",
    "\tfor i in f.readlines():\n",
    "\t\ttmp.append(i.strip('\\n'))\n",
    "\tif len(tmp)>0:\n",
    "\t\tdate_last_time = tmp[0]\n",
    "\t\turl__last_time = tmp[1]\n",
    "\telse:\n",
    "\t\tdate_last_time = \"\"\n",
    "\t\turl__last_time = \"\"\n",
    "\t#print(date_last_time,time_last_time,url__last_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#第一次 搜索列表\\nlast_html_str=\"\"\\nstart_height = 0\\nend_height = driver.execute_script(\"return document.body.scrollHeight\")\\nsleep(0.1)\\nfor i in range(start_height,end_height,200):\\n#    print(\\'\\r   %d\\'%i)\\n    sys.stdout.write(\\'\\r scrolling to height = \\'+str(i))\\n    driver.execute_script(\\'window.scrollTo(0,\\'+str(i)+\\')\\')\\n    sleep(0.1)\\n    \\nhtml_str = driver.page_source\\n#這個type 是string,  記錄瀏覽器html5，當前所有內文\\n    \\nsoup = BeautifulSoup(html_str, \"html.parser\")\\nfor block in soup.select(\\'.area_body\\')[1].select(\\'h2 a\\'):\\n    print(\"%s             %70s\"%(block.text,block[\\'href\\']))\\n    print(\"\\n\")\\n    \\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#第一次 搜索列表\n",
    "last_html_str=\"\"\n",
    "start_height = 0\n",
    "end_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "sleep(0.1)\n",
    "for i in range(start_height,end_height,200):\n",
    "#    print('\\r   %d'%i)\n",
    "    sys.stdout.write('\\r scrolling to height = '+str(i))\n",
    "    driver.execute_script('window.scrollTo(0,'+str(i)+')')\n",
    "    sleep(0.1)\n",
    "    \n",
    "html_str = driver.page_source\n",
    "#這個type 是string,  記錄瀏覽器html5，當前所有內文\n",
    "    \n",
    "soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "for block in soup.select('.area_body')[1].select('h2 a'):\n",
    "    print(\"%s             %70s\"%(block.text,block['href']))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#第二次 搜索列表\\n#\\n\\n#不知道為什麼，如果要用以下版本的找按鈕並點擊，如果頁面轉到該按鈕更下方的地方\\n#就會出現Message: unknown error: Element ... is not clickable at point  的error\\n#即使使用driver.find_element_by_xpath(\\'//*[@id=\"more\"]/div\\').click()以及sleep(5)也無效\\n#但是如果滾輪滾到網頁最上方，再按按鈕，就有效了\\ndriver.execute_script(\\'window.scrollTo(0,0)\\')\\nprint(driver.find_element_by_link_text(\"看更多內容\"))\\ndriver.find_element_by_link_text(\"看更多內容\").click()\\n\\n\\n#先睡一下，給他重新算一下參數，不然會拿到舊的scrollHeight\\nsleep(2)\\n\\nlast_html_str = html_str\\nstart_height = end_height\\nend_height = driver.execute_script(\"return document.body.scrollHeight\")\\n\\nfor i in range(start_height,end_height,200):\\n#    print(\\'\\r   %d\\'%i)\\n    sys.stdout.write(\\'\\r scrolling to height = \\'+str(i))\\n    driver.execute_script(\\'window.scrollTo(0,\\'+str(i)+\\')\\')\\n    sleep(0.1)\\n    \\n    \\n#這個type 是string,  記錄瀏覽器html5，當前所有內文\\nhtml_str = driver.page_source\\n\\nprint(\"\\nend\")\\n\\nsoup1 = BeautifulSoup(last_html_str).select(\\'.area_body\\')[1].select(\\'h2 a\\')\\nsoup2 = BeautifulSoup(html_str).select(\\'.area_body\\')[1].select(\\'h2 a\\')\\n\\nprint(len(soup1))\\nprint(len(soup2))\\n#print(soup1==soup2)\\nprint(\"update %d news\" %(len(soup2)-len(soup1)))\\n\\nfor i in range(len(soup1),len(soup2)):\\n    print(soup2[i])\\n    print(\\'\\n\\')\\n\\nsleep(1)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#第二次 搜索列表\n",
    "#\n",
    "\n",
    "#不知道為什麼，如果要用以下版本的找按鈕並點擊，如果頁面轉到該按鈕更下方的地方\n",
    "#就會出現Message: unknown error: Element ... is not clickable at point  的error\n",
    "#即使使用driver.find_element_by_xpath('//*[@id=\"more\"]/div').click()以及sleep(5)也無效\n",
    "#但是如果滾輪滾到網頁最上方，再按按鈕，就有效了\n",
    "driver.execute_script('window.scrollTo(0,0)')\n",
    "print(driver.find_element_by_link_text(\"看更多內容\"))\n",
    "driver.find_element_by_link_text(\"看更多內容\").click()\n",
    "\n",
    "\n",
    "#先睡一下，給他重新算一下參數，不然會拿到舊的scrollHeight\n",
    "sleep(2)\n",
    "\n",
    "last_html_str = html_str\n",
    "start_height = end_height\n",
    "end_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "for i in range(start_height,end_height,200):\n",
    "#    print('\\r   %d'%i)\n",
    "    sys.stdout.write('\\r scrolling to height = '+str(i))\n",
    "    driver.execute_script('window.scrollTo(0,'+str(i)+')')\n",
    "    sleep(0.1)\n",
    "    \n",
    "    \n",
    "#這個type 是string,  記錄瀏覽器html5，當前所有內文\n",
    "html_str = driver.page_source\n",
    "\n",
    "print(\"\\nend\")\n",
    "\n",
    "soup1 = BeautifulSoup(last_html_str).select('.area_body')[1].select('h2 a')\n",
    "soup2 = BeautifulSoup(html_str).select('.area_body')[1].select('h2 a')\n",
    "\n",
    "print(len(soup1))\n",
    "print(len(soup2))\n",
    "#print(soup1==soup2)\n",
    "print(\"update %d news\" %(len(soup2)-len(soup1)))\n",
    "\n",
    "for i in range(len(soup1),len(soup2)):\n",
    "    print(soup2[i])\n",
    "    print('\\n')\n",
    "\n",
    "sleep(1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th time\n",
      "\n",
      "end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\tony\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "120\n",
      "update 120 news in this iteration\n",
      "0\n",
      "2018-08-24 16:57\n",
      "美網／納達爾與史蒂芬斯 都不看好自己衛冕成功\n",
      "https://udn.com/news/story/7005/3327340?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "1\n",
      "2018-08-24 16:56\n",
      "情侶手扶梯放閃 網友見男方穿著大驚：剛雷殘嗎\n",
      "https://udn.com/news/story/8864/3328248?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "2\n",
      "2018-08-24 16:50\n",
      "影／蔡總統缺席金門823活動 呂秀蓮代答：剛斷交很忙\n",
      "https://udn.com/news/story/6656/3328381?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "3\n",
      "2018-08-24 16:48\n",
      "中職／伍佰登悍將主場演唱 台式搖滾襲捲新莊\n",
      "https://udn.com/news/story/7001/3328378?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "4\n",
      "2018-08-24 16:47\n",
      "女子吃飯被拍背 轉身手機秒遭偷走 \n",
      "https://udn.com/news/story/7335/3328333?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "5\n",
      "2018-08-24 16:47\n",
      "印尼留台校友:台灣有無法取代的獨特價值\n",
      "https://udn.com/news/story/7266/3328379?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "6\n",
      "2018-08-24 16:42\n",
      "嘉義地區2946戶停電 台電人員冒雨搶修\n",
      "https://udn.com/news/story/7314/3328365?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "7\n",
      "2018-08-24 16:40\n",
      "激發射箭隊奪牌 1支10分箭理事長頒100美元\n",
      "https://udn.com/news/story/12426/3328323?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "8\n",
      "2018-08-24 16:39\n",
      "台南停止上班上課 納骨塔封園起爭議\n",
      "https://udn.com/news/story/7326/3328358?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "9\n",
      "2018-08-24 16:39\n",
      "高雄港外7艘船舶擱淺人員均安\n",
      "https://udn.com/news/story/7470/3328357?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "10\n",
      "2018-08-24 16:36\n",
      "水災過後 當心這些疾病上身\n",
      "https://udn.com/news/story/7266/3328350?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "11\n",
      "2018-08-24 16:35\n",
      "【重磅快評】賴神拿上帝說嘴 災民求鬼也沒用 \n",
      "https://udn.com/news/story/12441/3328349?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "12\n",
      "2018-08-24 16:34\n",
      "南台淹大水 學者建議：打造不怕水淹的韌性城市\n",
      "https://udn.com/news/story/7314/3328347?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "13\n",
      "2018-08-24 16:32\n",
      "台鐵貨物列車瑞芳撞到人 男子命危身分不明\n",
      "https://udn.com/news/story/7315/3328346?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "14\n",
      "2018-08-24 16:31\n",
      "吳宗憲兒子一句話代價50萬！檢察官：希望他改過向善\n",
      "https://udn.com/news/story/7321/3328344?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "15\n",
      "2018-08-24 16:29\n",
      "影／豪大雨影響 台南後壁淹大水農夫無言\n",
      "https://udn.com/news/story/12440/3328337?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "16\n",
      "2018-08-24 16:23\n",
      "韓國瑜關心高雄淹水地區 強調治水防洪城郷要一致\n",
      "https://udn.com/news/story/7327/3328332?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "17\n",
      "2018-08-24 16:23\n",
      "Google打擊假消息 關閉伊朗網軍帳號\n",
      "https://udn.com/news/story/7088/3327370?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "18\n",
      "2018-08-24 16:23\n",
      "懷念黃信介 蔡英文：若他還在 會以台灣民主為榮\n",
      "https://udn.com/news/story/6656/3328331?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "19\n",
      "2018-08-24 16:21\n",
      "排球／楊怡真前進義大利聯賽 台灣女將第一人\n",
      "https://udn.com/news/story/7005/3328244?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "20\n",
      "2018-08-24 16:21\n",
      "吳敦義釋出善意 林為洲：堅持程序正義、參選到底\n",
      "https://udn.com/news/story/7324/3328330?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "21\n",
      "2018-08-24 16:21\n",
      "小米手環3來了！續航力約20天 售價865元\n",
      "https://udn.com/news/story/7087/3328325?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "22\n",
      "2018-08-24 16:21\n",
      "823暴雨為何成87水災翻版 氣象局分析原因\n",
      "https://udn.com/news/story/7266/3328319?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "23\n",
      "2018-08-24 16:19\n",
      "美國插手兩岸外交戰 陸籲「停止霸權主義」\n",
      "https://udn.com/news/story/7331/3328316?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "24\n",
      "2018-08-24 16:19\n",
      "台中登革熱拉警報再增3例 全到過開心農場\n",
      "https://udn.com/news/story/7325/3328315?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "25\n",
      "2018-08-24 16:18\n",
      "暴雨影響 台鐵行駛持續受限\n",
      "https://udn.com/news/story/7266/3328314?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "26\n",
      "2018-08-24 16:13\n",
      "【重磅快評】賴神好意思說台灣防災比日本行？\n",
      "https://udn.com/news/story/12441/3328310?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "27\n",
      "2018-08-24 16:11\n",
      "暴雨炸台 台鐵今日列車行駛計畫看這裡\n",
      "https://udn.com/news/story/7266/3328305?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "28\n",
      "2018-08-24 16:10\n",
      "高中女脖子被「種草莓」 大熱天包緊緊母親起疑\n",
      "https://udn.com/news/story/7317/3328303?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "29\n",
      "2018-08-24 16:10\n",
      "影／菲國馬尼拉灣驚現垃圾巨浪 汙染問題嚴重\n",
      "https://udn.com/news/story/6809/3328304?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "30\n",
      "2018-08-24 16:08\n",
      "台鐵後壁新營路線、斗南站西主線恢復正常行駛\n",
      "https://udn.com/news/story/7266/3328301?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "31\n",
      "2018-08-24 16:07\n",
      "鹽水4千多戶淹水 90歲婦躺床上無力逃生 令人心疼\n",
      "https://udn.com/news/story/12440/3328300?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "32\n",
      "2018-08-24 16:05\n",
      "暴雨水淹民宅老人倒臥水中身亡 死因待查\n",
      "https://udn.com/news/story/7315/3328297?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "33\n",
      "2018-08-24 16:02\n",
      "女壘／大陸王牌王蘭看中華隊：打擊好很多\n",
      "https://udn.com/news/story/12393/3328289?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "34\n",
      "2018-08-24 16:00\n",
      "體操／李智凱獲中國選手致敬 為台灣出了一口氣\n",
      "https://udn.com/news/story/12426/3328164?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "35\n",
      "2018-08-24 16:00\n",
      "射箭／亂風射倒中華隊 反曲弓混雙無緣獎牌\n",
      "https://udn.com/news/story/12393/3328271?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "36\n",
      "2018-08-24 15:59\n",
      "豪雨灌嘉南 雨量累積前50名統統在這\n",
      "https://udn.com/news/story/7266/3328270?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "37\n",
      "2018-08-24 15:56\n",
      " 麵包店稱「國軍定400餐盒又棄單」 網友質疑假消息問「想促銷」\n",
      "https://udn.com/news/story/8864/3328108?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "38\n",
      "2018-08-24 15:55\n",
      "亞運圖輯／射箭反曲弓混雙 中華隊止步八強\n",
      "https://udn.com/news/story/12426/3328269?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "39\n",
      "2018-08-24 15:54\n",
      "積水漸退 台鐵部分路線恢復行駛\n",
      "https://udn.com/news/story/7266/3328267?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "40\n",
      "2018-08-24 15:53\n",
      "特斯拉工廠附近一度起火 概念股臉綠\n",
      "https://udn.com/news/story/7251/3328116?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "41\n",
      "2018-08-24 15:53\n",
      "一張清朝時期古地圖告訴你 為何雨炸台南容易淹水\n",
      "https://udn.com/news/story/12440/3328127?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "42\n",
      "2018-08-24 15:51\n",
      "雨未歇！ 雲嘉等7縣市超大豪雨特報\n",
      "https://udn.com/news/story/7266/3328264?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "43\n",
      "2018-08-24 15:49\n",
      "吳宗憲子威脅炸北市府緩起訴 繳50萬處分金給國庫\n",
      "https://udn.com/news/story/7321/3328261?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "44\n",
      "2018-08-24 15:48\n",
      "田徑／大陸接力隊再傳傷兵 蘇炳添放眼百米9秒85\n",
      "https://udn.com/news/story/12393/3328260?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "45\n",
      "2018-08-24 15:44\n",
      "林依晨戴Tiffany 小藍盒緣分來自六月\n",
      "https://udn.com/news/story/7270/3328255?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "46\n",
      "2018-08-24 15:44\n",
      "颱風西馬隆襲日掀巨浪 300航班取消\n",
      "https://udn.com/news/story/6809/3328236?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "47\n",
      "2018-08-24 15:37\n",
      "收益欠佳 法航英航9月停飛德黑蘭航班\n",
      "https://udn.com/news/story/6811/3328195?from=udn-ch1_breaknews-1-0-news\n",
      "\n",
      "\n",
      "The data is up to date!!!!\n",
      "Update 47 data this time\n",
      "update 47 news totally\n"
     ]
    }
   ],
   "source": [
    "#本格是組裝上面兩個格子的結果，來達成更新n次的效果\n",
    "n = 200\n",
    "last_html_str=''\n",
    "html_str=''\n",
    "end_height = 0\n",
    "total_update_news_num = 0\n",
    "the_news_links = []\n",
    "stop = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    try:\n",
    "        print(\"%dth time\"%i)\n",
    "\n",
    "        driver.execute_script('window.scrollTo(0,0)')\n",
    "        driver.find_element_by_link_text(\"看更多內容\").click()\n",
    "        #先睡一下，給他重新算一下參數，不然會拿到舊的scrollHeight\n",
    "        sleep(2)\n",
    "\n",
    "\n",
    "        last_html_str = html_str\n",
    "        start_height = end_height\n",
    "        #滾滾輪到頁面最下方\n",
    "        end_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        sleep(2)\n",
    "        '''\n",
    "        for i in range(start_height,end_height,200):\n",
    "        #    print('\\r   %d'%i)\n",
    "            sys.stdout.write('\\r scrolling to height = '+str(i))\n",
    "            driver.execute_script('window.scrollTo(0,'+str(i)+')')\n",
    "            sleep(0.1)\n",
    "        '''\n",
    "\n",
    "        #這個type 是string,  記錄瀏覽器html5，當前所有內文\n",
    "        html_str = driver.page_source\n",
    "\n",
    "        print(\"\\nend\")\n",
    "        try:\n",
    "            last_news = BeautifulSoup(last_html_str).select('.area_body')[1].select('h2 a')\n",
    "        except:\n",
    "            last_news = []\n",
    "\n",
    "        current_news = BeautifulSoup(html_str).select('.area_body')[1].select('h2 a')\n",
    "\n",
    "        current_news_content = BeautifulSoup(html_str).select('.area_body')[1]\n",
    "\n",
    "        print(len(last_news))\n",
    "        print(len(current_news))\n",
    "        #rint(soup1==soup2)\n",
    "        print(\"update %d news in this iteration\" %(len(current_news)-len(last_news)))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        for i in range(len(last_news),len(current_news)):\n",
    "            print(i)\n",
    "\n",
    "            #由於UDN 的即實新聞列表並沒有 年份，但它的新聞稿內部有年份\n",
    "            #所以我嘗試進去每一個新聞取時間資料，速度會慢一些，但不會因為，跨到下一年而有一些bug\n",
    "            res = BeautifulSoup(requests.get('https://udn.com' + current_news[i]['href']).text)\n",
    "            date = res.select('div.story_bady_info_author')[0].select('span')[0].text\n",
    "            print(date)\n",
    "\n",
    "            title = current_news[i].text\n",
    "            print(title)\n",
    "            \n",
    "            url = 'https://udn.com' + current_news[i]['href']\n",
    "            print(url)\n",
    "            \n",
    "            print('\\n')\n",
    "            \n",
    "            \n",
    "            #這邊是再比較date是不是比date_last_time的時間點來的後面\n",
    "            #而剛剛好如果date比date_last_time的時間點來的後面，用一般字串比較的結果是相同的\n",
    "            #而且如果date_last_time是空字串，又剛剛好可以使得   \"任意 date\" > date_last_time\n",
    "            #可以做出 \"沒有上次的check point，把全部資料都爬過一遍的效果\"\n",
    "            \n",
    "            if date < date_last_time:\n",
    "                print(\"The data is up to date!!!!\\nUpdate %d data this time\"%total_update_news_num)\n",
    "                stop = True\n",
    "                break\n",
    "            elif date == date_last_time and url == url__last_time:\n",
    "                print(\"The data is up to date!!!!\\nUpdate %d data this time\"%total_update_news_num)\n",
    "                stop = True\n",
    "                break\n",
    "                \n",
    "            total_update_news_num = total_update_news_num + 1\n",
    "            \n",
    "            #這邊寫要存的URL\n",
    "            the_news_links.append([date,current_news[i].text,url])\n",
    "            \n",
    "            \n",
    "            ###記錄這次的是從哪一個新聞開始爬起\n",
    "            if len(timestamp) == 0 :\n",
    "                timestamp.append(date)\n",
    "                timestamp.append(url)\n",
    "        \n",
    "            \n",
    "        \n",
    "        if stop == True:\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        #traceback.print_exc()\n",
    "        print(\"tony log :  I guess the crawler reach the end of news, and the '看更多內容' is disappear!!\")\n",
    "        print(\"tony log :  check it first, then check the error log\")\n",
    "        stop = True\n",
    "\n",
    "sleep(1)\n",
    "print(\"update %d news totally\"% total_update_news_num)\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(the_news_links)>0:\n",
    "\n",
    "    with open(\"udn_news_links.txt\",'w') as f:\n",
    "        for i in the_news_links:\n",
    "#            f.write(i[0])\n",
    "#            f.write(i[1])\n",
    "            f.write(i[2])\n",
    "            f.write('\\n')\n",
    "\n",
    "    with open(\"udn_news_timestamp.txt\",'w') as f:\n",
    "        for i in timestamp:\n",
    "            f.write(i)\n",
    "            f.write('\\n')\n",
    "    #exit(0)\n",
    "else:\n",
    "    print(\"no update on udn_news_links\")\n",
    "    #exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\tony\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "res = BeautifulSoup(requests.get('https://udn.com/news/story/7314/3332366?from=udn-ch1_breaknews-1-0-news').text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "[<a href=\"https://udn.com\">udn</a>, <a href=\"/news/cate/2/6638\">要聞</a>]\n",
      "[<a href=\"/news/breaknews/1\" rel=\"/news/breaks_main_menu/1\">即時</a>, <a class=\"only_mobile\" href=\"/rank/pv/2\" id=\"m2\" title=\"熱門\"><b></b>熱門</a>, <a class=\"\" href=\"/news/cate/2/6638\" rel=\"/news/main_menu/2/6638\">要聞</a>, <a href=\"/vote2018/index\" id=\"m14\" rel=\"/static/pulldownmenu/vote2018/index.html\" target=\"_blank\">選舉</a>, <a href=\"https://stars.udn.com\" id=\"m14\" rel=\"/news/ch_main_menu/1022\" target=\"_blank\">娛樂</a>, <a class=\"\" href=\"/news/cate/2/7227\" rel=\"/news/main_menu/2/7227\">運動</a>, <a class=\"\" href=\"/news/cate/2/7225\" rel=\"/news/main_menu/2/7225\">全球</a>, <a class=\"\" href=\"/news/cate/2/6639\" rel=\"/news/main_menu/2/6639\">社會</a>, <a href=\"/topic/index\" id=\"m14\" rel=\"/static/pulldownmenu/topic/index.html\">專題</a>, <a class=\"\" href=\"/news/cate/2/6644\" rel=\"/news/main_menu/2/6644\">產經</a>, <a class=\"\" href=\"/news/cate/2/6645\" rel=\"/news/main_menu/2/6645\">股市</a>, <a href=\"http://house.udn.com/house/index\" id=\"m14\" rel=\"/news/ch_main_menu/1009\" target=\"_blank\">房市</a>, <a href=\"https://health.udn.com\" id=\"m14\" rel=\"/news/ch_main_menu/1005\" target=\"_blank\">健康</a>, <a class=\"\" href=\"/news/cate/2/6649\" rel=\"/news/main_menu/2/6649\">生活</a>, <a class=\"\" href=\"/news/cate/2/11195\" rel=\"/news/main_menu/2/11195\">文教</a>, <a class=\"\" href=\"/news/cate/2/6643\" rel=\"/news/main_menu/2/6643\">評論</a>, <a class=\"\" href=\"/news/cate/2/6641\" rel=\"/news/main_menu/2/6641\">地方</a>, <a class=\"\" href=\"/news/cate/2/6640\" rel=\"/news/main_menu/2/6640\">兩岸</a>, <a class=\"\" href=\"/news/cate/2/7226\" rel=\"/news/main_menu/2/7226\">數位</a>, <a href=\"/news/cindex/1013\" rel=\"/news/ch_main_menu/1013\">旅遊</a>]\n"
     ]
    }
   ],
   "source": [
    "#用class去找 nav 中的 udn新聞類別\n",
    "#select 用來抓class 或者 html tag ( ex <h1></h1> )\n",
    "'''\n",
    "tmp = res.select('.only_web')\n",
    "print(len(tmp))\n",
    "print(tmp[4].select('a'))\n",
    "\n",
    "\n",
    "#tmp = res.select('.div#nav.only_web')\n",
    "tmp = res.select('div')[6].select('a')[60:80]\n",
    "print(tmp)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "<a href=\"/news/cate/2/6638\">要聞</a>\n"
     ]
    }
   ],
   "source": [
    "#抓id法，用beautiful soup找nav\n",
    "\n",
    "id_is_nav = res.find(\"div\", {\"id\": \"nav\"})\n",
    "#print(id_is_nav)\n",
    "\n",
    "print(len(id_is_nav))\n",
    "\n",
    "'''\n",
    "cnt = 0\n",
    "for i in id_is_nav:\n",
    "    print('\\n\\n')\n",
    "    print(cnt)\n",
    "    print(i)\n",
    "    cnt = cnt + 1 \n",
    "'''\n",
    "\n",
    "print(id_is_nav.select('a')[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//*[@id=\"nav\"]\n",
    "//*[@id=\"nav\"]/a[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['要聞']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[<Element a at 0x804fc48>, <Element a at 0x7b29c48>]\n",
      "2\n",
      "udn\n",
      "要聞\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[<Element a at 0x7b29c48>]\n",
      "要聞\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nhtml = etree.parse(html, etree.HTMLParser())\\nresult = html.xpath(\\'//*[@id=\"nav\"]\\')\\nprint(result)\\nprint(result[0])\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#抓xpath法，用lxml找nav\n",
    "\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "html1 = res.text\n",
    "html = requests.get('https://udn.com/news/story/7314/3332366?from=udn-ch1_breaknews-1-0-news').text\n",
    "\n",
    "selector = etree.HTML(html)\n",
    "\n",
    "\n",
    "#sol 1\n",
    "print(selector.xpath('//*[@id=\"nav\"]/a[2]/text()'))\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "\n",
    "#sol 2\n",
    "links = selector.xpath('//*[@id=\"nav\"]/a')\n",
    "#links = selector.xpath('//*[@id=\"nav\"]/a[2]/text()')\n",
    "\n",
    "print(links)\n",
    "print(len(links))\n",
    "for link in links:\n",
    "    print(link.text)\n",
    "    \n",
    "print('\\n\\n\\n')\n",
    "\n",
    "#sol 3\n",
    "links = selector.xpath('//*[@id=\"nav\"]/a[2]')\n",
    "print(links)\n",
    "print(links[0].text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "html = etree.parse(html, etree.HTMLParser())\n",
    "result = html.xpath('//*[@id=\"nav\"]')\n",
    "print(result)\n",
    "print(result[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "水患剛過時就要談理性、科學，一定會有人覺得我在講幹話，所以您認為科學家只會講理想的幹話、沒有同理心，建議就別看這篇了。此外，如果您對以下的認知深信不疑，任誰也無法改變您的想法的話，也建議您看到這邊就好：\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "畢竟在認知落差如此大的情況下，筆者無法預期如何進行災害管理的溝通與討論。但如果您想再多了解一點關於極端氣候災害、要如何看待政府對水災的防治，以及如何嘗試自保自救，我們還是必須要回到「淹水的成因和因應」談起。\n",
      "\n",
      "「雨下在哪邊都一樣會淹水」是事實，但為什麼從政府官員口中說出來，會被當作是幹話呢？因為，確實有些事情是可以預先做的，但並不是單單只有「硬體建設」。所以如果此時有政客跳出來打包票說：「我來就可以保證不淹水」，就算他是大禹再世，這還是句幹話，等到那個政客上了台，還是會遇到一樣的問題的。況且，大禹當初也未必真把水治好了，所以像是這樣以大禹治水來評斷現今政府治水不力的論調，更是幹話中的幹話。\n",
      "\n",
      "\n",
      "\n",
      "歷史課本和童書上沒告訴你的大禹\n",
      "\n",
      "大禹治水，或許已耳熟能詳：大禹他爸鯀花了好多年，用築堤防堵的方式仍無法止住洪水氾濫，而且送了老命（但此說法不一），屈原後來還在《楚辭》〈天問〉中替他說兩句公道，可惜多數的書上也少有著墨。換了大禹來做後，他走訪各地、實行疏通排水、三過家門而不入，最後解決了洪水問題，也因此當上了天子共主，創建了夏朝。不過，你真的相信「不再有洪水」完全是大禹的功勞嗎？從目前一些研究的角度來看，比較有可能的情況是：大禹是個很幸運的水利署長，因天時地利人和，從政之路自此平步青雲（誤）。\n",
      " \n",
      "為什麼這麼說？從一篇2005年在中國發表的古氣候研究中便提出了一種看法。古氣候顯示在西元前4200年~西元前4000年間，是全球多處發生氣候異常的時期，而在西元前4000年之後，氣候趨於正常。因此從科學的角度合理推論，除了一方面大禹改變了治水之道以外，自然環境的變化如洪水發生頻率降低、河道逐漸穩定不再改道、天然的植被穩定生長而有了水土保持，也可能是洪災減少的原因。此外，再近一點的研究也指出當時曾有地震、堰塞湖崩潰等現象，帶來了非常極端的洪水事件。從上述兩種洪水來源來看，要將這樣危及民生的大規模洪水給消除，是不可能的任務，尤其是堰塞湖事件，如果鯀的治水不力是栽在這，我只能說他運氣實在太差了。\n",
      "\n",
      "\n",
      "\n",
      "為什麼沒有專家敢保證「永不淹水」？\n",
      "\n",
      "因為這種事根本不存在，要做出這樣的城市，就算蓋個50公尺高的馬莉亞之牆，再搭配個數萬台抽水機，還未必能萬無一失。最大的原因就是，我們根本不可能去找到最極端情況的氣候來設計工程，而且全世界都做不到。\n",
      " \n",
      "\n",
      "可是我看國外都會說200年不怕洪水什麼的啊！\n",
      " \n",
      "「200年洪水周期」一詞只是在形容降雨和洪水的「程度」，並不代表做了200年洪水周期設計的設施就保證200年內不會淹水，因為實際上這是在說明氣候的極端值統計結果，比較完整的說法是「200年洪水『再現』周期」。\n",
      "\n",
      "200年才會發生一次不等於每隔200年才遇到一次，有可能一下子連發生個兩次，之後又很久很久才會出現。而用200年來作為標準實施防洪排水設計，是極高規格的設計，全台也只有台北市針對淡水河能做到200年洪水周期的程度，而且還是花了上千億、歷經好幾任市長才做到，其它主要河川多數還是用100年洪水周期，而區域排水甚至只有10~25年的洪水周期。\n",
      " \n",
      "不能把所有的設計提高200年、300年再現周期嗎？除非我們有天文數字等級的治水預算。放眼國外，日本也會有發生洪災的時候（2018年西日本大豪雨）、2016年德國、法國也都因連日暴雨而有嚴重災害，這些國家都是我們政客口中常拿來作治水借鏡國家，但他們也還是會遇上有水災的情況。甚至，今年（2018）的三月在智利北部「阿塔卡馬沙漠」因「24小時降下24.4毫米雨量」而產生超嚴重洪災，這個雨量放在台灣，完全不會有問題，但在幾乎沒雨的沙漠，卻成了極端、設想之外的情境。所以才會說「雨下在哪邊都一樣會淹水」是事實，而我們要思考的，是如何因應這樣的事實。\n",
      "\n",
      "\n",
      "\n",
      "執政者不要再打包票、在野者不要再打口水戰\n",
      "\n",
      "在水災過後，若拿出科學論述來說明治水難以百分百防水，一定會有人問：不然我們每年花錢在建設是在花心酸的嗎？治水不就是要面對極端的洪水？\n",
      " \n",
      "但我們不妨換個角度想：我們會藉由各種護具和措施來預防運動傷害，但也不代表戴了護具就能百分之百不受傷，難道你會在正常使用護具、護具也沒有製造瑕玭的情況下受傷時，向護具廠商求償嗎？又如果是這樣，你會選擇完全不防護直接去做有風險的運動嗎？\n",
      " \n",
      "同樣的道理，以任何人為工程治水應該只能視為「其中一種保護措拖」，而不是「唯一的防治手段」。\n",
      " \n",
      "可悲的是，在政治或媒體的聲音中，總把工程治水當成唯一手段，期待自己是禹而對手是鯀、期待自己不會遇上極端事件，等到自創的神話被戳破時，再說對方沒有科學素養就好啦。\n",
      " \n",
      "缺乏防洪的科學素養是誰害的？身為地球科學的科普傳播者，自己也該負點責任（本文最後會附上相關的科普文延伸閱讀），只是，還有另一個問題根源：\n",
      " \n",
      "\n",
      "\n",
      "永遠沒有人去探討風險管理，是不是災害應變計畫不足、或甚至缺乏災害應變計畫，也沒有人去談科學傳播的問題，政論節目上只有被批判的專家而沒有真正的實話。這就是目前對於水災，我們最大的認知落差所在，如以下節錄的研究：\n",
      " \n",
      "居民在88風災災後的觀點整理節錄。摘自陳永森（2014），《極端氣候影響下潛在災害區居民環境識覺、調適行為之研究－以八八水災後屏東縣林邊鄉與佳冬鄉為例》：\n",
      "\n",
      "\n",
      "\n",
      "八八水災對於研究區之居民災害經驗與生活衝擊相當大，然而對於未來是否將出現更大的災害，在全球環境變遷以及極端氣候影響下，居民亦多認為應該相當有可能發生更大災害。在八八水災之後居民對於災害相關消息更具有敏感性，面對水災的精神壓力更大，防災行為積極性亦更主動，但也容易引發情緒騷動，且經由訊息傳播而使鄰里間關係與互動更加增強。\n",
      "\n",
      "\n",
      "\n",
      "民眾對於地方政府政策執行能力有相當程度之懷疑，但對於未來災害環境，又期待相信政府完成相關防洪與排水設施，可以有效避免災害的再次發生。但相對的，公部門並不認為設施能夠解決水患問題，卻以避災作為面對災害之處置，而非減災，此與居民之期許有著相當大的落差。\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "那我們到底該怎麼面對洪患威脅？\n",
      "\n",
      "各種疏洪、防治措施並不是沒用，而是光只做這些還不夠。就算加上近年來興起「海綿城市」概念，做了各種透水、滯洪池的規畫，也還是不夠。這種短期面向雖然做了大家很有感，但就算不偷工減料的做了，還是不能保證不怕淹水……所以我們才需要強調就長期而言，我們還需要做些什麼。\n",
      " \n",
      "防災宣導方面，私以為至少讓大家理解「自己可以做什麼」，像是購買颱風洪水險、主動去查詢淹水潛勢圖、了解氣象報告等等，都是不錯的方向。身為一個科普人，我認為自己即使有在做，但永遠都覺得還不夠，政府端做的……就更不用說了。所以，我並不認政府完全沒有責任，以災害管理和風險溝通方面，責任包括了政府、媒體、人民，政府教育民眾不力、媒體只會煽風點火，民眾只想看現成、有感的成果都是問題，今天如果大家已經知道淹水是必然，必須想點不同方法面對，絕對還能再減一點災情。\n",
      " \n",
      "此外，或許越來越多人知道水泥化的都市是不好的，會讓洪水的問題加劇，但人越來越多、都會區和工業區越來越多，永遠都止不住都市與建設的擴張。那怎麼辦？當有一天，如果我們的主政者開始去思考未來30年、50年的城市願景，去規畫所謂的施政藍圖、都市計畫，甚至是完整的「災害應變計畫」，就災害發生後的可能結果擬定相關應對策略，而非等事後發放補償金就好時，將順應自然的成份一併考量，並且加強與民眾對話而非單純為政治辯護，或許，也唯有如此，我們才有可能實現「少一點口水，永不怕洪水」的理想。\n",
      "\n",
      "※ 本文原發表自「地球故事書」，授權轉載。\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "｜延伸閱讀｜\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "編輯嚴選網上深度好文，延伸議題討論廣度。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\tony\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "html = requests.get('https://opinion.udn.com/opinion/story/5749/3333340').text\n",
    "res = BeautifulSoup(html)\n",
    "\n",
    "cnt = 0\n",
    "for i in res.select('p'):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "\n",
      "823中南部暴雨成災，副總統陳建仁24日帶全家人到金門度假3天遭批評。聯合報系資料照 分享   facebook     \n",
      "1\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "\n",
      "國民黨金門縣長參選人楊鎮浯表示，發生在民國47年的「八二三砲戰」今年適逢60周年，這場戰役雖傷亡慘重，但確保了台澎金馬的安全。身為中華民國總統及三軍統帥的蔡英文，卻缺席8月23日在金門舉行的紀念儀式。但823中南部暴雨成災，副總統陳建仁24日竟帶全家人到金門度假3天。我們當然樂見政府官員多來金門旅遊觀光，這簡直毫無同理心，甚至到了冷血的地步。\n",
      "2\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "\n",
      "楊鎮浯說，總統的缺席這對當年浴血奮戰，甚至犧牲性命的烈士及其眷屬情何以堪？也對落下47萬多發砲彈的金門與這片土地承受苦難的鄉親們，極不尊重。身為金門立委，楊鎮浯要表達最嚴正的抗議與憤怒。\n",
      "3\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "\n",
      "楊鎮浯指出，即便是過去同樣是民進黨執政時的陳水扁前總統，也曾2度親赴金門參與八二三紀念活動。而國民黨的馬英九前總統則曾3度蒞金主持紀念大會，其中一次還是2008年的「八二三砲戰」50周年。\n",
      "4\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "\n",
      "楊鎮浯表示，今年是八二三歷經一甲子極具紀念意義的時刻，是身為國家元首最該來金門致意之際，蔡英文卻因為意識形態與政治因素選擇刻意不來，這已經夠令人萬分遺憾了。詎料，民進黨副秘書長徐佳青還補上一刀說，八二三是共產黨和國民黨打仗」，不是跟民進黨打仗，根本不值得紀念。這種用狹隘的政黨利益去扭曲這場戰役的神聖價值，是污辱了中華民國，更是在金門的這段歷史傷口上灑鹽，鎮浯深感不齒與痛心。\n",
      "5\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "\n",
      "楊鎮浯說，尤令人匪夷所思的是，八二三中南部暴雨成災，就當災民最需要政府慰助的時候，竟傳出副總統陳建仁24日帶全家人到金門度假3天。我們當然樂見政府官員多來金門旅遊觀光，但萬事莫如救災急，副總統彼時理應襄助蔡總統帶領行政團隊全心投入救災，卻帶著全家人來金門遊玩。這簡直毫無同理心，甚至到了冷血的地步。政府高官來與不來金門，考驗著民進黨的智慧，也在挑戰金門鄉親以及全國人民的觀感與底線。\n",
      "6\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "***************\n",
      "\n",
      "**********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\tony\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#html = requests.get('https://udn.com/news/story/7005/3332859').text\n",
    "#html = requests.get('https://opinion.udn.com/opinion/story/5749/3333340').text\n",
    "html = requests.get('https://udn.com/news/story/6656/3334135').text\n",
    "#html = requests.get('https://udn.com/news/story/6656/3334430').text\n",
    "\n",
    "res = BeautifulSoup(html)\n",
    "\n",
    "cnt = 0\n",
    "for i in res.select('p'):\n",
    "    print(cnt)\n",
    "    cnt = cnt +1\n",
    "    #print(\"asdfasdf::\",i)\n",
    "    \n",
    "    '''\n",
    "    print(i.text)\n",
    "    \n",
    "    in_p = i.find_all(True) \n",
    "    #print(in_p);\n",
    "    \n",
    "    if not in_p == []:\n",
    "        print(\"---------------------------\")\n",
    "        print(i)\n",
    "        print(\"---------------------------\")\n",
    "        print(in_p[0])\n",
    "        print(\"---------------------------\")\n",
    "        #print(in_p[0].select('img'))\n",
    "        #print(\"---------------------------\")\n",
    "    ''' \n",
    "    \n",
    "    \n",
    "    print(\"***************\\n***************\\n***************\\n***************\\n***************\\n\")\n",
    "    \n",
    "    if i.select('script') == []:\n",
    "        \n",
    "        print(i.text)\n",
    "    else:\n",
    "        \n",
    "        print('**********\\n\\n')\n",
    "    \n",
    "\n",
    "    '''\n",
    "    tmp = i.text;\n",
    "    delete_tag = tmp.find( \"photo_center photo-story\")\n",
    "    if not delete_tag == None:\n",
    "        _ = delete_tag.extract()\n",
    "        \n",
    "        print(\"asdfasdfasdfasdfasdfasdfasdfasdf\")\n",
    "    print(tmp)\n",
    "    #print(\"asdfasdf::\",i.text.strip())\n",
    "    ''' \n",
    "    #print(\"asdfasdf::\",i.text)\n",
    "    \n",
    "    #a_tag\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-135-86646e0a2381>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-135-86646e0a2381>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    </div>\"\"\")asdfasd\u001b[0m\n\u001b[1;37m                     \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "In [13]: soup = BeautifulSoup(\"\"\"<div id=\"content\">\n",
    "I want to keep this<br /><div id=\"blah\">I want to remove this</div>\n",
    "</div>\"\"\")\n",
    "\n",
    "In [14]: soup = BeautifulSoup(\"\"\"<div id=\"content\">\n",
    "   ....: I want to keep this<br /><div id=\"blah\">I want to remove this</div>\n",
    "   ....: </div>\"\"\")\n",
    "\n",
    "In [15]: blah = soup.find(id='blah')\n",
    "\n",
    "In [16]: _ = blah.extract()\n",
    "\n",
    "In [17]: soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
